{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import unicodedata\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import string\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\modelagem_principal\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'download.pytorch.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Extract data\n",
    "response = requests.get(\n",
    "    'https://download.pytorch.org/tutorial/data.zip',\n",
    "    verify=False\n",
    ")\n",
    "\n",
    "data, labels = [], []\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as zfile:\n",
    "    for filename in [\n",
    "        f \n",
    "        for f in zfile.namelist() \n",
    "        if f.endswith('.txt') and f.startswith('data/names')\n",
    "    ]:\n",
    "        with zfile.open(filename) as file:\n",
    "            lines = file.read().decode('utf-8').strip().split('\\n')\n",
    "            names = [\n",
    "                unicodedata.normalize(\n",
    "                    'NFKD', \n",
    "                    line\n",
    "                ).encode('ascii', 'ignore').decode('utf-8')\n",
    "                for line in lines\n",
    "            ]\n",
    "            category = filename.split('/')[-1].split('.')[0]\n",
    "            temp_labels = np.repeat(category, len(names))\n",
    "            \n",
    "            data.extend(names)\n",
    "            labels.extend(temp_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Arabic', '0'],\n",
       "       ['Chinese', '1'],\n",
       "       ['Czech', '2'],\n",
       "       ['Dutch', '3'],\n",
       "       ['English', '4'],\n",
       "       ['French', '5'],\n",
       "       ['German', '6'],\n",
       "       ['Greek', '7'],\n",
       "       ['Irish', '8'],\n",
       "       ['Italian', '9'],\n",
       "       ['Japanese', '10'],\n",
       "       ['Korean', '11'],\n",
       "       ['Polish', '12'],\n",
       "       ['Portuguese', '13'],\n",
       "       ['Russian', '14'],\n",
       "       ['Scottish', '15'],\n",
       "       ['Spanish', '16'],\n",
       "       ['Vietnamese', '17']], dtype='<U11')"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categories = label_encoder.classes_\n",
    "\n",
    "def label_to_tensor(label, encoder):\n",
    "    label = label if isinstance(label, list) else [label]\n",
    "    return torch.LongTensor(\n",
    "        encoder.transform(label).reshape(-1, 1)\n",
    "    ).to(device)\n",
    "\n",
    "np.vstack([categories, label_encoder.transform(categories)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = string.ascii_letters + \" .,;'-/:\" + '0123456789'\n",
    "\n",
    "def name_to_tensor(name):\n",
    "    tensor = torch.zeros(len(name), len(dictionary)).to(device)\n",
    "    for i, char in enumerate(name):\n",
    "        try:\n",
    "            tensor[i][dictionary.index(char)] = 1\n",
    "        except:\n",
    "            raise ValueError(f'Character {char} not in dictionary')\n",
    "    return tensor\n",
    "\n",
    "name_to_tensor('Edy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Classes Within Each Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(data, labels, encoder, size):\n",
    "    data = data.copy()\n",
    "    labels = labels.copy()\n",
    "    \n",
    "    data_batch, labels_batch = [], []\n",
    "\n",
    "    categories, _ = np.unique(labels, return_counts=True)\n",
    "\n",
    "    for cat in categories:\n",
    "        idxs_cat = [i for i, l in enumerate(labels) if l == cat]\n",
    "\n",
    "        selected_idx = np.random.choice(idxs_cat, size=size, replace=True)\n",
    "\n",
    "        \n",
    "        data_sample = np.array(data)[selected_idx]\n",
    "        labels_sample = np.array(labels)[selected_idx]      \n",
    "        \n",
    "        data_batch.extend(data_sample)\n",
    "        labels_batch.extend(labels_sample)\n",
    "\n",
    "    \n",
    "    data_tns = [name_to_tensor(d) for d in data_batch]\n",
    "    labels_tns = label_to_tensor(labels_batch, encoder=encoder)\n",
    "    return data_tns, labels_tns\n",
    "\n",
    "data_batch, rotulos_batch = sample_batch(\n",
    "  data, labels, encoder=label_encoder, size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.recurrent = nn.RNNCell(input_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, name):\n",
    "        h = torch.zeros(1, self.hidden_size).to(device)\n",
    "        \n",
    "        for char in name:\n",
    "            h = self.recurrent(char.unsqueeze(0), h)\n",
    "        \n",
    "        output =self.output(h)\n",
    "        output = self.activation(output)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, criterion, optimizer, data, labels):\n",
    "    model.train()\n",
    "\n",
    "    loss_epoca = []\n",
    "\n",
    "    for name, label in zip(data, labels):\n",
    "        output = model(name)\n",
    "        loss = criterion(output, label)\n",
    "        loss_epoca.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return np.array(loss_epoca).mean(), np.array(loss_epoca).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (recurrent): RNNCell(70, 256)\n",
      "  (output): Linear(in_features=256, out_features=18, bias=True)\n",
      "  (activation): LogSoftmax(dim=1)\n",
      ")\n",
      "2.784439 0.48785064\n",
      "2.6883578 0.5690623\n",
      "2.7020793 0.6311553\n",
      "2.7034342 0.55232114\n",
      "2.6746027 0.5526362\n",
      "2.6145952 0.56827426\n",
      "2.6231782 0.5710179\n",
      "2.5376334 0.56354606\n",
      "2.5659747 0.6169963\n",
      "2.5164654 0.59072524\n",
      "2.4344406 0.70919186\n",
      "2.3424273 0.74793226\n",
      "2.2299218 0.7966887\n",
      "2.1566365 0.82914597\n",
      "2.0521865 0.8440369\n",
      "2.113647 0.9492568\n",
      "2.169059 0.9362336\n",
      "2.1218321 0.8855945\n",
      "2.0815325 0.8750496\n",
      "2.0778499 0.8690164\n",
      "2.0237267 0.88405126\n",
      "1.9807699 0.8873127\n",
      "2.0654137 0.97155064\n",
      "2.1196823 0.940999\n",
      "2.0822706 0.94067717\n",
      "2.0631886 0.92870706\n",
      "2.0547864 0.9654269\n",
      "2.074694 0.96843135\n",
      "2.023165 0.99979055\n",
      "2.0120852 0.9161863\n",
      "1.9230075 0.88972884\n",
      "1.9693134 0.95069516\n",
      "1.8894516 0.891388\n",
      "1.8910749 0.92503774\n",
      "1.8827585 0.96744275\n",
      "1.8466097 0.9440686\n",
      "1.8283675 0.9961492\n",
      "1.8137956 0.9543905\n",
      "1.8545247 1.0211815\n",
      "1.9163531 1.0181613\n",
      "1.9153602 1.0293472\n",
      "1.9655445 0.9859263\n",
      "1.9113257 1.0073656\n",
      "1.9579767 1.019925\n",
      "1.9818958 1.0377027\n",
      "1.9384103 1.0265933\n",
      "1.9161335 1.0193805\n",
      "1.9239306 1.0400075\n",
      "1.9549682 1.0186418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21308/675919773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdata_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mloss_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21308/523646101.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, criterion, optimizer, data, labels)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss_epoca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\modelagem_principal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\modelagem_principal\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1560\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21308/336243.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RNN(len(dictionary), 256, len(categories))\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "optim_parameters = {\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 1e-7\n",
    "}\n",
    "optimizer = torch.optim.Adam(model.parameters(), **optim_parameters)\n",
    "\n",
    "for epoch in range(200):\n",
    "    data_batch, labels_batch = sample_batch(data, labels, label_encoder, 50)\n",
    "    loss_mean, loss_std = train_step(model, criterion, optimizer, data_batch, labels_batch)\n",
    "    print(loss_mean, loss_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelagem_principal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
