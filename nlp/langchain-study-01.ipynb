{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import Field, BaseModel\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.globals import set_debug\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "set_debug(False)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7fc83047c370>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fc83047dc90>, root_client=<openai.OpenAI object at 0x7fc830422fb0>, root_async_client=<openai.AsyncOpenAI object at 0x7fc83047c3a0>, temperature=0.8, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM Setup\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.8,\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Template Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a 7-day Rio de Janeiro travel itinerary for a family with 2 childrens that likes beach.\n"
     ]
    }
   ],
   "source": [
    "# Testing PromptTemplate\n",
    "\n",
    "inputs = {\n",
    "    'n_days': 7,\n",
    "    'n_children': 2,\n",
    "    'activity': 'beach',\n",
    "    'location': 'Rio de Janeiro'\n",
    "}\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Create a {n_days}-day {location} travel itinerary for a family with {n_children} childrens that likes {activity}.\"\n",
    ")\n",
    "\n",
    "format = prompt_template.format(**inputs)\n",
    "    \n",
    "print(format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SystemMessage:  You are the narrator of an RPG adventure.\n",
      "HumanMessage:   Tell me about the city we are exploring.\n",
      "AIMessage:      You are in Eudoria, an ancient city known for its mystical ruins and bustling markets.\n",
      "HumanMessage:   I want to know more about the main temple.\n",
      "AIMessage:      The Temple of Solara is the spiritual heart of Eldoria, famous for its vast collection of sacred relics and ancient stories.\n"
     ]
    }
   ],
   "source": [
    "# Testing ChatPromptTemplate\n",
    "\n",
    "inputs = {\n",
    "    'city': 'Eudoria'\n",
    "}\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are the narrator of an RPG adventure.\"),\n",
    "        (\"human\", \"Tell me about the city we are exploring.\"),\n",
    "        (\"ai\", \"You are in {city}, an ancient city known for its mystical ruins and bustling markets.\"),\n",
    "        (\"human\", \"I want to know more about the main temple.\"),\n",
    "        (\"ai\", \"The Temple of Solara is the spiritual heart of Eldoria, famous for its vast collection of sacred relics and ancient stories.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "dialog = chat_template.format_messages(**inputs)\n",
    "\n",
    "for msg in dialog:\n",
    "    print('{:<15} {}'.format(type(msg).__name__ + ':', msg.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Certainly! Here are some words and phrases that are frequently used in the context of an interview for a data scientist position:\\n\\n1. **Data Analysis**\\n2. **Machine Learning**\\n3. **Algorithms**\\n4. **Statistical Modeling**\\n5. **Data Visualization**\\n6. **Big Data**\\n7. **Predictive Analytics**\\n8. **Data Mining**\\n9. **Programming Languages** (Python, R, SQL)\\n10. **Feature Engineering**\\n11. **Data Cleaning**\\n12. **A/B Testing**\\n13. **Hypothesis Testing**\\n14. **Business Intelligence**\\n15. **Data Wrangling**\\n16. **Neural Networks**\\n17. **Deep Learning**\\n18. **Model Evaluation**\\n19. **Cross-Validation**\\n20. **Data Governance**\\n21. **ETL (Extract, Transform, Load)**\\n22. **Cloud Computing** (AWS, Azure, Google Cloud)\\n23. **Collaboration**\\n24. **Communication Skills**\\n25. **Problem-Solving**\\n26. **Critical Thinking**\\n27. **Domain Knowledge**\\n28. **Data Ethics**\\n29. **Data Architecture**\\n30. **Visualization Tools** (Tableau, Power BI, Matplotlib)\\n\\nThese terms can help you prepare for discussions about your skills, experiences, and the technical aspects of the role during the interview.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 270, 'prompt_tokens': 22, 'total_tokens': 292, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-2ad5e068-1cc6-4582-87ae-f9246558fa48-0', usage_metadata={'input_tokens': 22, 'output_tokens': 270, 'total_tokens': 292})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    ")\n",
    "\n",
    "llm.invoke(\"Suggest words frequently used in the following context: Interview for a data scientist position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Analytics\" is a word frequently used in the context of an interview for a data scientist position.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 23, 'total_tokens': 43, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0a78720-72f1-492c-91f2-1e6943a7528c-0', usage_metadata={'input_tokens': 23, 'output_tokens': 20, 'total_tokens': 43})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Suggest a word frequently used in the following context: Interview for a data scientist position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Algorithm\" is a word frequently used in the context of an interview for a data scientist position. It\\'s a core concept in data science, encompassing the methods and procedures used for data analysis, machine learning, and problem-solving.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 23, 'total_tokens': 68}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-cda4480e-8533-4388-9eac-c85e522e7cca-0', usage_metadata={'input_tokens': 23, 'output_tokens': 45, 'total_tokens': 68})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Word(BaseModel):\n",
    "    word: str = Field(description=\"The suggested word\")\n",
    "    context: str = Field(description=\"The context in which the word is to be used\")\n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    word: str = Field(description=\"The suggested word\")\n",
    "    sentences: List[str] = Field(description=\"List of sentences\")\n",
    "\n",
    "word_parser = JsonOutputParser(pydantic_object=Word)\n",
    "word_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Suggest a word frequently used in the following context: Interview for a data scientist position\n",
    "    \"\"\"\n",
    ")\n",
    "# word_template.invoke({\"context\": \"Interview for a data scientist position\"})\n",
    "# word_chain = word_template | llm #| word_parser\n",
    "llm.invoke('Suggest a word frequently used in the following context: Interview for a data scientist position')\n",
    "# response = word_chain.invoke(\n",
    "#     {\"context\": \"Interview for a data scientist position\"}\n",
    "# )\t\n",
    "# print(response)\n",
    "\n",
    "# sentence_parser = JsonOutputParser(pydantic_object=Sentences)\n",
    "# sentece_template = PromptTemplate(\n",
    "#     template=\"\"\"\n",
    "#         Suggest 3 sentences in the context of {context} using the word '{word}' for a English Speaking Training.\n",
    "#         ---\n",
    "#         {output_template}\n",
    "#     \"\"\",\n",
    "#     input_variables=[\"context\", \"word\"],\n",
    "#     partial_variables={\"output_template\": sentence_parser.get_format_instructions()},\n",
    "# )\n",
    "# sentence_chain = sentece_template | llm | sentence_parser\n",
    "\n",
    "# full_chain = word_chain | sentence_chain\n",
    "\n",
    "# response = word_chain.invoke(\n",
    "#     {\"context\": \"Interview for a data scientist position\"}\n",
    "# )\t\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A4eIggcpTRuNoK5JlcAAOh9A4SpX8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A word frequently used in the context of interviewing for a data scientist position is \"algorithm.\"', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725671590, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_bbdc8689fd', usage=CompletionUsage(completion_tokens=18, prompt_tokens=23, total_tokens=41))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Suggest a word frequently used in the following context: Interview for a data scientist position\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    ")\n",
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pais': 'Brasil',\n",
       " 'cores': 'Verde, amarelo, azul e branco',\n",
       " 'historia': \"A bandeira do Brasil foi adotada em 1889 e é composta por um fundo verde com um losango amarelo no centro, contendo uma esfera azul com uma faixa branca contendo a inscrição 'Ordem e Progresso'. As cores representam a família real, a Casa de Bragança, a Casa de Habsburgo e a Casa de Lorena, respectivamente.\"}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.5,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Defina a classe com a estrutura desejada\n",
    "class Bandeira(BaseModel):\n",
    "    pais: str = Field(description=\"nome do pais\")\n",
    "    cores: str = Field(description=\"cor principal da bandeira\")\n",
    "    historia: str = Field(description=\"história da bandeira\")\n",
    "\n",
    "# Defina o prompt que será utilizado para pergunta\n",
    "flag_query = \"Me fale da bandeira do Brasil\"\n",
    "\n",
    "# Defina a estrutura que será utilizada para processar a saída\n",
    "parseador_bandeira = JsonOutputParser(pydantic_object=Bandeira)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Responda a pergunta do usuário.\\n{instrucoes_formato}\\n{pergunta}\\n\",\n",
    "    input_variables=[\"pergunta\"],\n",
    "    partial_variables={\"instrucoes_formato\": parseador_bandeira.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parseador_bandeira\n",
    "\n",
    "chain.invoke({\"pergunta\": flag_query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
